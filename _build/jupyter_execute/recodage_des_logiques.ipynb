{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4f087d-917e-4795-b015-5563bad171f3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import markdown as md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd4c526-78a3-4773-85e3-d0c2d8c4e594",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#url = 'https://drive.google.com/file/d/0B6GhBwm5vaB2ekdlZW5WZnppb28/view?usp=sharing'\n",
    "#path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "#df = pd.read_csv(path)\n",
    "#print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015fec04-d055-417a-8329-35c08937864e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory :  /home/aymeric/python-scripts/anses_medialab/analyse_mixte/ansesreport\n",
      "Path base :  /home/aymeric/python-scripts/anses_medialab/datas/\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"Current directory : \", current_directory)\n",
    "\n",
    "aymeric =  \"/home/aymeric/python-scripts/anses_medialab/datas/\" #aymeric\n",
    "jp = '~/Dropbox/Mac/Desktop/CRD Anses/all3/' # Jean Philippe\n",
    "jp_index = '~/Dropbox/Mac/Desktop/CRD Anses/code/indexation_results/' # Jean Philippe index\n",
    "\n",
    "if 'aymeric' in current_directory:\n",
    "    path_base = aymeric\n",
    "    index=f\"{path_base}index_allall_domainsexhaustive.csv\"\n",
    "elif 'Mac' in current_directory:\n",
    "    path_base = jp\n",
    "    index=f'{jp_index}index_allall_domainsexhaustive.csv'\n",
    "elif 'd:/Projects' in current_directory:\n",
    "    path_base = \"d:/Projects/Medialab/\"\n",
    "    index=f\"{path_base}index_allall_domainsexhaustive.csv\"\n",
    "\n",
    "print(\"Path base : \", path_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628b20c",
   "metadata": {},
   "source": [
    "# Chargement des données et nettoyage des données\n",
    "\n",
    "## Facebook\n",
    "\n",
    "### Les postes facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513e81cd-9e59-4aad-ac89-b3eff1e60de3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aymeric/anaconda3/envs/analyse_tweets/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Chargement du corpus facebook (les posts)\n",
    "data_file = path_base+\"datas_facebook/data_ct_glypho_pest_roundup_etc.csv.zip\"#,line_terminator='\\n',index=False)\n",
    "    ## fichier des posts facebook\n",
    "fb_posts = pd.read_csv(data_file, dtype={\"account_id\":str})\n",
    "fb_posts = fb_posts.loc[fb_posts[\"account_platform\"] == \"Facebook\"]\n",
    "fb_posts[\"account_publication\"] = fb_posts.groupby(\"account_name\")[\"id\"].transform(\"count\")\n",
    "\n",
    "len(fb_posts)\n",
    "\n",
    "fb_posts.loc[fb_posts[\"account_url\"] == \"https://www.facebook.com/934946709937770\", \"account_id\"] = \"934946709937770\"\n",
    "fb_posts.loc[fb_posts[\"account_url\"] == \"https://www.facebook.com/934946709937770\", \"account_handle\"] = \"SteveFah237\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c214f4",
   "metadata": {},
   "source": [
    "### La liste des pages et groupes facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b8fb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51345"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chargement de la liste des comptes facebook\n",
    "fb_account = pd.read_csv(f\"{path_base}datas_facebook/all_account_facebook.csv\", sep =\"\\t\", dtype={\"account_id\":str})\n",
    "len(fb_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066efd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"/home/aymeric/python-scripts/anses_medialab/analyse_mixte/fb_and_tw_annotated_account2.csv\", sep = \"\\t\", dtype={\"user_id\":str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44153198",
   "metadata": {},
   "source": [
    "## Twitter\n",
    "\n",
    "### Le corpus de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc8e376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aymeric/anaconda3/envs/analyse_tweets/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (39,50,51,52) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4823/3188974484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'.zip'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analyse_tweets/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analyse_tweets/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analyse_tweets/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#a changer localement\n",
    "#media_filename='../medias/data/dwld_pesticides_and_cie_mediacloud_stories.csv.zip'\n",
    "#tweet_path='../twitter/tweets_pesticides and cie/*'\n",
    "#fb_filename='../facebook/data/glypho_1percent_posts.csv.gz'\n",
    "#fb_filename=\"../facebook/data/post_glyphosate_since_2010_new_sourcing.csv\"\n",
    "\n",
    "##donnees aymeric\n",
    "tweet_path = f\"{path_base}/tweets_pesticides/tweets_pesticides and cie/*\"\n",
    "\n",
    "import glob\n",
    "#paths = glob.glob('d:/Projects/Medialab/Anses/tweetstotal/*')\n",
    "paths=glob.glob(tweet_path)\n",
    "paths\n",
    "\n",
    "tweets=pd.DataFrame()\n",
    "for p in [f for f in paths if not '.zip' in f]:    \n",
    "    df=pd.read_csv(p, dtype={\"user_id\":str})\n",
    "    tweets=tweets.append(df, ignore_index=True)\n",
    "tweets=tweets.drop_duplicates()\n",
    "tweets['date'] = pd.to_datetime(tweets['local_time']).dt.date\n",
    "#tweets\n",
    "\n",
    "print (len(tweets))\n",
    "tweets=tweets.dropna(subset=['text'])\n",
    "tweets = tweets.reset_index()\n",
    "\n",
    "tweets = tweets.loc[~(tweets['text'].str.contains('N.H.L.', case=False, regex=False, na=False))]\n",
    "print (len(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc41e3",
   "metadata": {},
   "source": [
    "### La liste des comptes\n",
    "\n",
    "Le script ci-dessous sert à uniformiser les \"user_name\", \"user_screen_name\" et \"user_tweets\" (nombre de tweets publiés par un compte), car il arrive que la \"valeur\" de ces variables changent avec le temps : les propriétaires des comptes peuvent changer leur noms et le nombre de tweets publiés évoluent par définition avec le temps.\n",
    "\n",
    "Lorsqu'un compte a changé plusieurs fois de noms (un même \"user_id\" est associé à plusieurs \"user_name\" ou \"user_screen_name\"), nous avons choisi de garder le plus récent. Il en va de même pour le nombre de tweets publiés : nous avons gardé la dernière valeur connue.\n",
    "\n",
    "Par ailleurs, du fait qu'il existe des homonymes (plusieurs \"user_id\" peuvent avoir le même \"user_name\"), nous travaillerons de préférences avec les \"user_id\" ou les \"user_screen_name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ebdddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2817/320026786.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tw_account[\"ratio_posts\"] = tw_account[\"account_publication\"] / tw_account[\"total_posts\"] *100\n"
     ]
    }
   ],
   "source": [
    "tw_account0 = tweets[['id', 'timestamp_utc','local_time',\n",
    "       'user_screen_name', 'user_location', \n",
    "       'user_id', 'user_name', 'user_description',\n",
    "       'user_url', 'user_tweets', 'user_followers',\n",
    "       'user_friends', 'user_likes', 'user_lists', 'user_created_at',\n",
    "       'user_timestamp_utc', 'date']]\n",
    "\n",
    "total_post = tw_account0[[\"user_id\", 'user_tweets']].sort_values(by=[\"user_id\",'user_tweets'], ascending = [True, False]).drop_duplicates(subset = [\"user_id\"], keep = \"first\")\n",
    "\n",
    "\n",
    "total_post = total_post.rename(columns={\"user_tweets\": \"total_posts\"})\n",
    "\n",
    "recent_scr_name = tw_account0[[\"user_id\",\"user_screen_name\", 'timestamp_utc']].sort_values(by=[\"user_id\",'timestamp_utc'], ascending = [True, False]).drop_duplicates(subset = [\"user_id\"], keep = \"first\")\n",
    "\n",
    "recent_name = tw_account0[[\"user_id\",\"user_name\", 'timestamp_utc']].sort_values(by=[\"user_id\",'timestamp_utc'], ascending = [True, False]).drop_duplicates(subset = [\"user_id\"], keep = \"first\")\n",
    "\n",
    "recent_name = recent_name.merge(recent_scr_name, how = \"left\", on = [\"user_id\", 'timestamp_utc']).merge(total_post, how = \"left\", on = [\"user_id\"])\n",
    "\n",
    "recent_name = recent_name.drop(columns = [\"timestamp_utc\"])\n",
    "\n",
    "tw_account2 = tw_account0.drop(columns = [\"user_screen_name\", \"user_name\"]).merge(recent_name, how = \"left\", on = [\"user_id\"])\n",
    "tweets = tweets.drop(columns = [\"user_screen_name\", \"user_name\"]).merge(recent_name, how = \"left\", on = [\"user_id\"])\n",
    "\n",
    "\n",
    "\n",
    "tw_account2 = tw_account2[['id',\n",
    "       'user_id', 'user_name','user_screen_name', \"total_posts\",\n",
    "        'user_description', 'user_location', \n",
    "       'user_url', 'user_tweets', 'user_followers',\n",
    "       'user_friends', 'user_likes', 'user_lists', 'user_created_at',\n",
    "       'user_timestamp_utc', 'date']]\n",
    "\n",
    "tw_account2[\"account_publication\"] = tw_account2.groupby([\"user_id\"])[\"id\"].transform(\"count\")\n",
    "tw_account = tw_account2.drop_duplicates(subset = [\"user_id\"])\n",
    "tw_account[\"ratio_posts\"] = tw_account[\"account_publication\"] / tw_account[\"total_posts\"] *100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629fa65",
   "metadata": {},
   "source": [
    "### Le fichier des pages et groupes annotés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d1b1c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platform\n",
       "Facebook    230\n",
       "twitter     464\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_f = df0.loc[df0[\"platform\"] == \"Facebook\"]\n",
    "df_t = df0.loc[df0[\"platform\"] == \"twitter\"]\n",
    "\n",
    "t = tweets[[\"user_id\", \"user_screen_name\", \"user_name\", 'total_posts']].drop_duplicates()\n",
    "\n",
    "\n",
    "f = fb_account[['account_id', 'account_url',  'account_publication','total_posts',\n",
    "       'ratio_posts']].rename(\n",
    "    columns = {\"account_id\" : \"user_id\", \"account_url\": \"user_account_url\"})\n",
    "\n",
    "\n",
    "\n",
    "df_f = df_f.drop(columns = [\"user_id\", 'account_publication','total_posts', 'ratio_posts']).merge(f, how = \"left\", on = [\"user_account_url\"])\n",
    "df_t =  df_t.drop(columns = [\"user_id\", 'total_posts']).merge(t, how = \"left\", on = [\"user_screen_name\", \"user_name\"])\n",
    "df_t =  df_t.drop(columns = [\"user_screen_name\", \"user_name\"]).merge(\n",
    "    tw_account[[\"user_id\",\"user_screen_name\", \"user_name\"]], how = \"left\", on = [\"user_id\"])\n",
    "df = pd.concat([df_t,df_f])\n",
    "\n",
    "\n",
    "df = df[['user_id', 'user_screen_name','user_name',\n",
    "         'index', 'Comment', 'Type_entite', 'Genre', 'User_role2', 'User_role',\n",
    "       'world', 'User_world', 'User_world2', 'Orientation', 'main_thematic',\n",
    "       'user_description', 'associated_fb_url', 'associated_website',\n",
    "       'user_account_url', 'user_location', 'total_posts',\n",
    "       'account_publication', 'ratio_posts', 'user_created_at', 'platform',\n",
    "       'user_tag', 'associated_tw_url', 'account_type',\n",
    "       'account_page_admin_top_country']]\n",
    "\n",
    "df.groupby([\"platform\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e0d61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fb_account[['account_id', 'account_url',  'account_publication','total_posts', \"account_name\", \"account_handle\", \n",
    "       'ratio_posts']].rename(\n",
    "    columns = {\"account_id\" : \"user_id\", \"account_url\": \"user_account_url\",\n",
    "              \"account_name\":\"user_name\", \"account_handle\" : \"user_screen_name\", })\n",
    "\n",
    "df_f[\"annote\"] = \"True\"\n",
    "df_f2 = f.merge(df_f.drop(columns = [\"user_id\", 'account_publication','total_posts', \n",
    "                                     'ratio_posts', 'index', \"user_screen_name\", \"user_name\"]), how = \"left\", on = [\"user_account_url\"])\n",
    "df_f2[\"platform\"] = \"Facebook\"\n",
    "df_f2.loc[df_f2[\"annote\"].isnull()==False, \"annoted\"] = \"True\"\n",
    "df_f2.loc[df_f2[\"annote\"].isnull()==True, \"annoted\"] = \"False\"\n",
    "\n",
    "df_t[\"annote\"] = \"True\"\n",
    "df_t2 =  t.merge(df_t.drop(columns = [\"user_id\", 'total_posts', \"index\"]), how = \"left\", on = [\"user_screen_name\", \"user_name\"])\n",
    "df_t2 =  tw_account[[\"user_id\",\"user_screen_name\", \"user_name\", \n",
    "                    'account_publication','total_posts', \n",
    "                    'ratio_posts']].merge(df_t2.drop(columns = [\"user_screen_name\", \n",
    "                                                                \"user_name\", 'account_publication','total_posts', \n",
    "                                                                'ratio_posts']), how = \"left\", on = [\"user_id\"])\n",
    "df_t2[\"platform\"] = \"twitter\"\n",
    "df_t2.loc[df_t2[\"annote\"].isnull()==False, \"annoted\"] = \"True\"\n",
    "df_t2.loc[df_t2[\"annote\"].isnull()==True, \"annoted\"] = \"False\"\n",
    "df = pd.concat([df_f2, df_t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "235a9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {\"main_thematic\" : \"Logics\"})\n",
    "\n",
    "df[\"Logics\"] = df['Logics'].replace(\n",
    "    {\"Rationaliste\" : \"Positivistes\",\n",
    "    'Mouvments anti-ogm': 'Mouvements anti-ogm'})\n",
    "\n",
    "df[\"Synthetic_logics\"] = df['Logics'].replace(\n",
    "    {'Produits pharmaceutiques et cosmétiques': \"Marketing_logic\", \n",
    "      'Commerce et grande distribution': \"Marketing_logic\",\n",
    "     'Industrie agroalimentaire' : 'Agroindustrial_perspectives',\n",
    "     'Matériels agricoles': 'Agroindustrial_perspectives', \n",
    "     'Industrie phytosanitaires et biocides': 'Agroindustrial_perspectives',\n",
    "     'Positivistes' : 'Positivistic_logic', 'Défense des agricultures conventionnelles' :\"Positivistic_logic\",\n",
    "     'Mouvements écologistes' : 'Ecological_perspectives', \n",
    "     'Justice environnementale': 'Ecological_perspectives',\n",
    "     'Mouvements anti-ogm':'Ecological_perspectives',\n",
    "     'Contre le monde de Monsanto et cie':'Ecological_perspectives',\n",
    "     \"Protection de l'environnement\":'Ecological_perspectives',\n",
    "     'Défense des agricultures non-conventionnelles' : 'Pesticide_free_agriculture',\n",
    "     'Lutte contre les pesticides': 'Pesticide_free_agriculture',\n",
    "     'Apiculture': 'Pesticide_free_agriculture', \n",
    "     'Mouvement de victimes des pesticides':'Pesticide_free_agriculture',\n",
    "     'Santé': \"Health_perspectives\",\n",
    "     'Actualité' : 'Comment_the_news',\n",
    "     'Bien-être animal' : 'Ecological_perspectives'\n",
    "      })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d524775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synthetic_logics\n",
       "Agroindustrial_perspectives     31\n",
       "Comment_the_news                86\n",
       "Ecological_perspectives        223\n",
       "Health_perspectives             38\n",
       "Marketing_logic                 32\n",
       "Pesticide_free_agriculture     143\n",
       "Positivistic_logic             137\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Synthetic_logics\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81331393",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_posts.columns\n",
    "posts = fb_posts[['id', 'title', 'caption', 'message', 'account_type',\n",
    "       'description', 'date', 'account_id', \"account_name\", \"account_handle\",\n",
    "       'account_page_admin_top_country']].rename(columns ={'account_id':'user_id', \n",
    "                                                           \"account_name\" : 'user_name', \n",
    "                                                           \"account_handle\":\"user_screen_name\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "274a8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = df[[\"platform\", \"annoted\", \"user_id\", \"user_screen_name\", \"user_name\", \"user_account_url\", \"Type_entite\", \"Genre\", \"User_world\", \"Logics\", \"Synthetic_logics\", \"account_publication\", \"total_posts\", \"ratio_posts\"]]\n",
    "df02 = df[[\"platform\", \"annoted\", \"user_id\", \"user_screen_name\", \"user_name\", \"user_account_url\", \"Type_entite\", \"User_world2\", \"Logics\", \"Synthetic_logics\", \"account_publication\", \"total_posts\", \"ratio_posts\"]].rename(columns={\"User_world2\":\"User_world\"})\n",
    "\n",
    "what_platform = {\"twitter\":\"tweets\", \"Facebook\":\"Facebook posts\"}\n",
    "\n",
    "for origin in [\"twitter\", \"Facebook\"]:\n",
    "    if origin == \"twitter\":\n",
    "        df_t1 =  tweets[['id', 'timestamp_utc', 'local_time', 'text',\n",
    "               'user_id', 'user_screen_name', 'user_name', 'mentioned_names', \n",
    "               'mentioned_ids', 'hashtags', 'date']].merge(\n",
    "            df01.loc[df[\"platform\"] == \"twitter\"], how = \"left\", on = [\"user_id\"])\n",
    "\n",
    "        df_t2 =  tweets[['id', 'timestamp_utc', 'local_time', 'text',\n",
    "               'user_id', 'user_screen_name', 'user_name', 'mentioned_names',\n",
    "               'mentioned_ids', 'hashtags', 'date']].merge(\n",
    "            df02.loc[df[\"platform\"] == \"twitter\"], how = \"left\", on = [\"user_id\"])\n",
    "        \n",
    "        df_t = pd.concat([df_t1, df_t2]).drop_duplicates()#.dropna(subset=[\"Type_entite\"])\n",
    "\n",
    "        df_t['date'] = pd.to_datetime(df_t['date'], infer_datetime_format=True)\n",
    "\n",
    "        df_t['yearmonth']=(df_t['date'].dt.strftime('%Y-%m'))\n",
    "\n",
    "        df_t['date'] = df_t['date'].dt.date\n",
    "        \n",
    "        \n",
    "        df_t[\"platform\"] = \"twitter\"\n",
    "        df_t = df_t[['platform', \"annoted\", 'id', 'text', 'date', 'mentioned_names', \n",
    "                     'mentioned_ids', 'hashtags', 'user_id', 'user_screen_name_x', 'user_name_x', \n",
    "                     'user_screen_name_y', 'user_name_y', 'user_account_url',  'Type_entite', 'Genre', \n",
    "                     'User_world', 'Logics', 'Synthetic_logics', 'account_publication', \n",
    "                     \"total_posts\", 'ratio_posts', 'yearmonth']]\n",
    "\n",
    "    elif origin == \"Facebook\":\n",
    "        df_f1 =  posts.merge(\n",
    "            df01.loc[df[\"platform\"] == \"Facebook\"], how = \"left\", on = [\"user_id\"])\n",
    "        \n",
    "        df_f2 =  posts.merge(\n",
    "            df02.loc[df[\"platform\"] == \"Facebook\"], how = \"left\", on = [\"user_id\"])\n",
    "\n",
    "        df_f = pd.concat([df_f1, df_f2]).drop_duplicates().dropna(subset=[\"message\"])\n",
    "\n",
    "        df_f['date'] = pd.to_datetime(df_f['date'], infer_datetime_format=True)\n",
    "\n",
    "        df_f['yearmonth']=(df_f['date'].dt.strftime('%Y-%m'))\n",
    "\n",
    "        df_f['date'] = df_f['date'].dt.date\n",
    " \n",
    "        df_f[\"text\"] = df_f.title.astype(str).str.cat(df_f.message.astype(str), sep='. ', na_rep =\"\")\n",
    "        \n",
    "        df_f[\"platform\"] = \"Facebook\"\n",
    "        \n",
    "        df_f = df_f[['platform', \"annoted\", 'id', 'text', 'date', 'account_type', 'user_id',\n",
    "           'user_screen_name_x', 'user_name_x', 'user_screen_name_y', 'user_name_y', \n",
    "                     'user_account_url',  'Type_entite', 'Genre', 'User_world',\n",
    "           'Logics', 'Synthetic_logics', 'account_publication', \"total_posts\", 'ratio_posts', 'yearmonth']]\n",
    "\n",
    "\n",
    "\n",
    "dftext = pd.concat([df_t, df_f]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aefda47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d51463aefb74d5584ad0a17717ad680"
      },
      "text/plain": [
       "         platform annoted                               id  \\\n",
       "0         twitter   False              1212156531434754049   \n",
       "1         twitter    True              1212156152076787712   \n",
       "2         twitter   False              1212149065057624064   \n",
       "3         twitter   False              1212144705628192768   \n",
       "4         twitter   False              1212143182022107136   \n",
       "...           ...     ...                              ...   \n",
       "1913113  Facebook    True  301107319917469_293236150712037   \n",
       "1913114  Facebook    True  301107319917469_183074215121895   \n",
       "1913115  Facebook    True  301107319917469_110973229022457   \n",
       "1913116  Facebook    True  301107319917469_205534019527895   \n",
       "1913117  Facebook    True  301107319917469_309155912436409   \n",
       "\n",
       "                                                      text        date  \\\n",
       "0        @Mimookthecowboy C’est sûrement à cause du chl...  2019-12-31   \n",
       "1        @coquelicots_ Déjà faudrait il commencer par n...  2019-12-31   \n",
       "2        Deux nouveaux pesticides nocifs pour les abeil...  2019-12-31   \n",
       "3        Chuchoteur 2020 (Journal annuel du Collectif I...  2019-12-31   \n",
       "4        Pesticides: les Coquelicots collent les SDHI! ...  2019-12-31   \n",
       "...                                                    ...         ...   \n",
       "1913113  Cela vaut-il le coup de manger bio pour éviter...  2011-12-22   \n",
       "1913114  Des puces RFID au secours des abeilles - LeMon...  2011-12-21   \n",
       "1913115  http://www.menustoxiques.fr/pdf/doc_menubio_15...  2011-12-20   \n",
       "1913116  Témoignages : victimes des pesticides. Des tém...  2011-12-08   \n",
       "1913117  20-30 mars 2012 - Semaine pour les Alternative...  2011-11-25   \n",
       "\n",
       "         mentioned_names        mentioned_ids             hashtags  \\\n",
       "0        mimookthecowboy                  NaN                  NaN   \n",
       "1           coquelicots_  1039098468994822146  bioindustriel|lobby   \n",
       "2                    NaN                  NaN                  NaN   \n",
       "3           changefrance            603139314                  NaN   \n",
       "4           coquelicots_  1039098468994822146                  NaN   \n",
       "...                  ...                  ...                  ...   \n",
       "1913113              NaN                  NaN                  NaN   \n",
       "1913114              NaN                  NaN                  NaN   \n",
       "1913115              NaN                  NaN                  NaN   \n",
       "1913116              NaN                  NaN                  NaN   \n",
       "1913117              NaN                  NaN                  NaN   \n",
       "\n",
       "                    user_id                          user_account_url  ...  \\\n",
       "0                 600997333                                       NaN  ...   \n",
       "1        776804948705153025            https://twitter.com/fermedupre  ...   \n",
       "2        951470420728991744                                       NaN  ...   \n",
       "3        705331587941060608                                       NaN  ...   \n",
       "4                2312970457                                       NaN  ...   \n",
       "...                     ...                                       ...  ...   \n",
       "1913113     301107319917469  https://www.facebook.com/301107319917469  ...   \n",
       "1913114     301107319917469  https://www.facebook.com/301107319917469  ...   \n",
       "1913115     301107319917469  https://www.facebook.com/301107319917469  ...   \n",
       "1913116     301107319917469  https://www.facebook.com/301107319917469  ...   \n",
       "1913117     301107319917469  https://www.facebook.com/301107319917469  ...   \n",
       "\n",
       "                          User_world  \\\n",
       "0                                NaN   \n",
       "1               Les mondes agricoles   \n",
       "2                                NaN   \n",
       "3                                NaN   \n",
       "4                                NaN   \n",
       "...                              ...   \n",
       "1913113  Les mondes de l'information   \n",
       "1913114  Les mondes de l'information   \n",
       "1913115  Les mondes de l'information   \n",
       "1913116  Les mondes de l'information   \n",
       "1913117  Les mondes de l'information   \n",
       "\n",
       "                                            Logics  \\\n",
       "0                                              NaN   \n",
       "1        Défense des agricultures conventionnelles   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "...                                            ...   \n",
       "1913113                Lutte contre les pesticides   \n",
       "1913114                Lutte contre les pesticides   \n",
       "1913115                Lutte contre les pesticides   \n",
       "1913116                Lutte contre les pesticides   \n",
       "1913117                Lutte contre les pesticides   \n",
       "\n",
       "                   Synthetic_logics account_publication total_posts  \\\n",
       "0                               NaN                 8.0    235217.0   \n",
       "1                Positivistic_logic              1486.0     18206.0   \n",
       "2                               NaN                 2.0     18111.0   \n",
       "3                               NaN               121.0     10447.0   \n",
       "4                               NaN              1776.0     13265.0   \n",
       "...                             ...                 ...         ...   \n",
       "1913113  Pesticide_free_agriculture               863.0      1335.0   \n",
       "1913114  Pesticide_free_agriculture               863.0      1335.0   \n",
       "1913115  Pesticide_free_agriculture               863.0      1335.0   \n",
       "1913116  Pesticide_free_agriculture               863.0      1335.0   \n",
       "1913117  Pesticide_free_agriculture               863.0      1335.0   \n",
       "\n",
       "         ratio_posts  yearmonth   account_type        user_screen_name  \\\n",
       "0           0.003401    2019-12            NaN          Topshattabaton   \n",
       "1           8.162144    2019-12            NaN              fermedupre   \n",
       "2           0.011043    2019-12            NaN            anthosimon86   \n",
       "3           1.158227    2019-12            NaN          SteibelMartine   \n",
       "4          13.388617    2019-12            NaN                PHurlaux   \n",
       "...              ...        ...            ...                     ...   \n",
       "1913113    64.644195    2011-12  facebook_page  SemaineAlterPesticides   \n",
       "1913114    64.644195    2011-12  facebook_page  SemaineAlterPesticides   \n",
       "1913115    64.644195    2011-12  facebook_page  SemaineAlterPesticides   \n",
       "1913116    64.644195    2011-12  facebook_page  SemaineAlterPesticides   \n",
       "1913117    64.644195    2011-11  facebook_page  SemaineAlterPesticides   \n",
       "\n",
       "                                            user_name  \n",
       "0                                              Jolyne  \n",
       "1                Olivier Garnier - Ferme du pré 🚜🌻🐝💉💉  \n",
       "2                                     Anto Simon ⭐️⭐️  \n",
       "3                                     STEIBEL MARTINE  \n",
       "4                                    Philippe Hurlaux  \n",
       "...                                               ...  \n",
       "1913113  Semaine pour les alternatives aux pesticides  \n",
       "1913114  Semaine pour les alternatives aux pesticides  \n",
       "1913115  Semaine pour les alternatives aux pesticides  \n",
       "1913116  Semaine pour les alternatives aux pesticides  \n",
       "1913117  Semaine pour les alternatives aux pesticides  \n",
       "\n",
       "[1913118 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bamboolib\n",
    "dftext.loc[dftext[\"user_screen_name_y\"].isnull() == True,\"user_screen_name\"]= dftext[\"user_screen_name_x\"]\n",
    "dftext.loc[dftext[\"user_screen_name_y\"].isnull() == False,\"user_screen_name\"]= dftext[\"user_screen_name_y\"]\n",
    "dftext.loc[dftext[\"user_name_y\"].isnull() == True,\"user_name\"]= dftext[\"user_name_x\"]\n",
    "dftext.loc[dftext[\"user_name_y\"].isnull() == False,\"user_name\"]= dftext[\"user_name_y\"]\n",
    "dftext = dftext.drop(columns=[\"user_screen_name_x\", \"user_screen_name_y\", \"user_name_x\", \"user_name_y\", \"index\"])\n",
    "dftext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ed2e7",
   "metadata": {},
   "source": [
    "### Le fichier des périodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b507743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a changer localement\n",
    "#df0 = pd.read_csv(all_corpus, sep = \"\\t\")\n",
    "dfseg = pd.read_csv(\"/home/aymeric/python-scripts/anses_medialab/datas/segmentation_common_freq.csv\", sep = \"\\t\")\n",
    "\n",
    "segment = dfseg[[\"yearmonth\", \"segm\", \"origin\"]].rename(columns={\"origin\":\"platform\"})\n",
    "\n",
    "segment[\"platform\"] = segment[\"platform\"].replace({\"facebook\":\"Facebook\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e1b422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dftext.merge(segment, how = \"left\", on = [\"platform\", \"yearmonth\"])\n",
    "dfs[\"start_segment\"] = dfs.groupby(['platform','segm'])[\"date\"].transform('min')\n",
    "dfs[\"end_segment\"] = dfs.groupby(['platform','segm'])[\"date\"].transform('max')\n",
    "dfs[\"text\"] =  dfs.text.apply(lambda x : x.replace('\\r', ' '))\n",
    "dfs[\"text\"] =  dfs.text.apply(lambda x : x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d581954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv(f'/home/aymeric/python-scripts/anses_medialab/datas/tweets_and_posts_with_annotated_account.csv', sep = \",\", index=False, doublequote=True)\n",
    "df.to_csv(f'/home/aymeric/python-scripts/anses_medialab/datas/all_annotated_account.csv', sep = \",\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69d939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "hide_input": false,
  "kernelspec": {
   "display_name": "analyse_tweets",
   "language": "python",
   "name": "analyse_tweets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}